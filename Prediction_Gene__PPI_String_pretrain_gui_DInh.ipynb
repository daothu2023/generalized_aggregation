{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daothu2023/generalized_aggregation/blob/main/Prediction_Gene__PPI_String_pretrain_gui_DInh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgwuCX9IngXk",
        "outputId": "aaae3894-5f9d-4969-aea1-d8874f44329c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BED6Lk9Qq-Q",
        "outputId": "07a4c4ef-c89e-4d5d-f7a8-b7f7f98bc33b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix1nSm8RtoK-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Äá»c dá»¯ liá»‡u\n",
        "edges_df = pd.read_csv('/content/drive/My Drive/PPI_STRING/ppi_for_gnn_filled.csv')\n",
        "features_df = pd.read_csv('/content/drive/My Drive/PPI_STRING/features_for_CESC.csv', index_col=0)\n",
        "labels_df = pd.read_csv('/content/drive/My Drive/PPI_STRING/CESC_labels(0_1).csv')\n",
        "\n",
        "# Danh sÃ¡ch gene vÃ  Ã¡nh xáº¡ index\n",
        "genes_from_edges = set(edges_df['protein1']).union(set(edges_df['protein2']))\n",
        "all_genes = sorted(genes_from_edges)\n",
        "node_to_idx = {gene: i for i, gene in enumerate(all_genes)}\n",
        "idx_to_node = {i: gene for gene, i in node_to_idx.items()}\n",
        "\n",
        "# edge_index\n",
        "edges = edges_df[['protein1', 'protein2']].dropna()\n",
        "edge_index = torch.tensor([[node_to_idx[a], node_to_idx[b]]\n",
        "                           for a, b in edges.values if a in node_to_idx and b in node_to_idx],\n",
        "                          dtype=torch.long).t().contiguous()\n",
        "\n",
        "# Táº¡o ma tráº­n Ä‘áº·c trÆ°ng vá»›i placeholder 0\n",
        "feature_dim = features_df.shape[1]\n",
        "x_matrix = np.zeros((len(all_genes), feature_dim))\n",
        "has_feature = np.zeros(len(all_genes), dtype=bool)\n",
        "\n",
        "# GÃ¡n Ä‘áº·c trÆ°ng chÆ°a chuáº©n hÃ³a\n",
        "for gene in features_df.index:\n",
        "    if gene in node_to_idx:\n",
        "        idx = node_to_idx[gene]\n",
        "        x_matrix[idx] = features_df.loc[gene].values\n",
        "        has_feature[idx] = True\n",
        "\n",
        "# TÃ­nh trung bÃ¬nh hÃ ng xÃ³m cho cÃ¡c node khÃ´ng cÃ³ Ä‘áº·c trÆ°ng\n",
        "neighbors_dict = {i: [] for i in range(len(all_genes))}\n",
        "for src, dst in edge_index.t().tolist():\n",
        "    neighbors_dict[src].append(dst)\n",
        "    neighbors_dict[dst].append(src)\n",
        "\n",
        "for i in range(len(all_genes)):\n",
        "    if not has_feature[i]:\n",
        "        neighbor_feats = [x_matrix[n] for n in neighbors_dict[i] if has_feature[n]]\n",
        "        if neighbor_feats:\n",
        "            x_matrix[i] = np.mean(neighbor_feats, axis=0)\n",
        "\n",
        "# Táº¡o nhÃ£n\n",
        "labels_map = {row['Gene']: row['Labels'] for _, row in labels_df.iterrows()}\n",
        "y = torch.full((x_matrix.shape[0],), -1, dtype=torch.long)\n",
        "for gene, label in labels_map.items():\n",
        "    if gene in node_to_idx:\n",
        "        y[node_to_idx[gene]] = int(label)\n",
        "\n",
        "# Chuyá»ƒn x_matrix sang tensor (chÆ°a chuáº©n hÃ³a lÃºc nÃ y!)\n",
        "x = torch.tensor(x_matrix, dtype=torch.float)\n",
        "data = Data(x=x, edge_index=edge_index, y=y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPcKounDvceP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score, average_precision_score\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# ======================= 1. Äá»‹nh nghÄ©a cÃ¡c mÃ´ hÃ¬nh =======================\n",
        "class GCNEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.fc1 = nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.out_proj = nn.Linear(hidden_channels, in_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.out_proj(x)\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.fc1 = nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.fc2 = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# ======================= 2. HÃ m huáº¥n luyá»‡n & Ä‘Ã¡nh giÃ¡ =======================\n",
        "def evaluate(model, data, mask, loss_fn):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_mask = mask & (data.y != -1)\n",
        "        out = model(data.x, data.edge_index)\n",
        "        probs = F.softmax(out, dim=1)\n",
        "        loss = loss_fn(out[valid_mask], data.y[valid_mask]).item()\n",
        "        preds = out[valid_mask].argmax(dim=1)\n",
        "        acc = accuracy_score(data.y[valid_mask].cpu(), preds.cpu())\n",
        "        auprc = average_precision_score(data.y[valid_mask].cpu(), probs[valid_mask][:, 1].cpu())\n",
        "    return acc, auprc, loss\n",
        "\n",
        "def train_one_epoch(model, data, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    mask = data.train_mask & (data.y != -1)\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = loss_fn(out[mask], data.y[mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def oversample_features(x, y, idx):\n",
        "    labels = y[idx].cpu().numpy()\n",
        "    class_counts = Counter(labels)\n",
        "    max_class = max(class_counts.values())\n",
        "    new_x, new_y = [], []\n",
        "\n",
        "    for c in class_counts:\n",
        "        c_idx = idx[(y[idx] == c)]\n",
        "        repeats = max_class - class_counts[c]\n",
        "        repeat_idx = c_idx.repeat(int(repeats // len(c_idx)) + 1)[:repeats]\n",
        "        new_x.append(x[repeat_idx])\n",
        "        new_y.append(y[repeat_idx])\n",
        "    return torch.cat([x] + new_x), torch.cat([y] + new_y)\n",
        "\n",
        "# ======================= 3. HÃ m chÃ­nh: pretrain + fine-tune =======================\n",
        "def run_pretrain_finetune_pipeline(data_raw, hidden_channels=32):\n",
        "    labeled_idx = torch.where(data_raw.y != -1)[0]\n",
        "    labeled_y = data_raw.y[labeled_idx]\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=45)\n",
        "\n",
        "    accs, auprcs = [], []\n",
        "\n",
        "    for fold, (train_val_idx, test_idx) in enumerate(skf.split(labeled_idx, labeled_y)):\n",
        "        print(f\"\\nğŸ“‚ Fold {fold+1}/5\")\n",
        "\n",
        "        sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=fold+1)\n",
        "        train_idx, val_idx = next(sss.split(train_val_idx, labeled_y[train_val_idx]))\n",
        "\n",
        "        train_nodes = labeled_idx[train_val_idx][train_idx]\n",
        "        val_nodes = labeled_idx[train_val_idx][val_idx]\n",
        "        test_nodes = labeled_idx[test_idx]\n",
        "\n",
        "        # 1. Chuáº©n hoÃ¡ Dá»® LIá»†U TOÃ€N Bá»˜ báº±ng scaler tá»« TRAIN\n",
        "        x_np = data_raw.x.cpu().numpy()\n",
        "        scaler = StandardScaler()\n",
        "        x_scaled = scaler.fit(data_raw.x[train_nodes].cpu()).transform(x_np)\n",
        "        data = Data(x=torch.tensor(x_scaled, dtype=torch.float32),\n",
        "                    edge_index=data_raw.edge_index.clone(),\n",
        "                    y=data_raw.y.clone())\n",
        "\n",
        "        # 2. Pretrain trÃªn toÃ n bá»™ dá»¯ liá»‡u (khÃ´ng nhÃ£n)\n",
        "        encoder = GCNEncoder(data.num_node_features, hidden_channels)\n",
        "        optimizer = torch.optim.Adam(encoder.parameters(), lr=0.01)\n",
        "        for epoch in range(200):\n",
        "            encoder.train()\n",
        "            optimizer.zero_grad()\n",
        "            x_masked = data.x.clone()\n",
        "            mask = torch.rand_like(x_masked) < 0.15\n",
        "            x_masked[mask] = 0\n",
        "            out = encoder(x_masked, data.edge_index)\n",
        "            loss = F.mse_loss(out, data.x)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # 3. Táº¡o GCN & gÃ¡n trá»ng sá»‘\n",
        "        model = GCN(data.num_node_features, hidden_channels, out_channels=2)\n",
        "        model.conv1.load_state_dict(encoder.conv1.state_dict())\n",
        "        model.conv2.load_state_dict(encoder.conv2.state_dict())\n",
        "        model.fc1.load_state_dict(encoder.fc1.state_dict())\n",
        "\n",
        "        # 4. Táº¡o train/val/test mask\n",
        "        x_train = data.x[train_nodes]\n",
        "        y_train = data.y[train_nodes]\n",
        "        x_resampled, y_resampled = oversample_features(x_train, y_train, torch.arange(len(train_nodes)))\n",
        "\n",
        "        data.x = torch.cat([data.x, x_resampled[len(train_nodes):]], dim=0)\n",
        "        data.y = torch.cat([data.y, y_resampled[len(train_nodes):]], dim=0)\n",
        "\n",
        "        n_total = data.x.shape[0]\n",
        "        train_mask = torch.zeros(n_total, dtype=torch.bool)\n",
        "        val_mask = torch.zeros(n_total, dtype=torch.bool)\n",
        "        test_mask = torch.zeros(n_total, dtype=torch.bool)\n",
        "\n",
        "        train_mask[train_nodes] = True\n",
        "        train_mask[len(train_nodes):] = True\n",
        "        val_mask[val_nodes] = True\n",
        "        test_mask[test_nodes] = True\n",
        "\n",
        "        data.train_mask = train_mask\n",
        "        data.val_mask = val_mask\n",
        "        data.test_mask = test_mask\n",
        "\n",
        "        # 5. Train fine-tune\n",
        "        y_train_all = torch.cat([y_train, y_resampled[len(train_nodes):]]).cpu().numpy()\n",
        "        weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_all), y=y_train_all)\n",
        "        loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(weights, dtype=torch.float32))\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "        best_val_loss = float('inf')\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(1, 201):\n",
        "            train_loss = train_one_epoch(model, data, optimizer, loss_fn)\n",
        "            train_acc, train_auprc, _ = evaluate(model, data, train_mask, loss_fn)\n",
        "            val_acc, val_auprc, val_loss = evaluate(model, data, val_mask, loss_fn)\n",
        "\n",
        "            print(f\"Epoch {epoch:03d} | Train Acc: {train_acc:.4f} | AUPRC: {train_auprc:.4f} || \"\n",
        "                  f\"Val Acc: {val_acc:.4f} | AUPRC: {val_auprc:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = model.state_dict()\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "            if patience_counter >= 40:\n",
        "                break\n",
        "         # â¬‡ï¸ LÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t theo fold\n",
        "        model_path = f\"/content/drive/My Drive/PPI_STRING/Best_model_pretrain/CESCrun2_best_model_fold{fold+1}.pth\"\n",
        "        torch.save(best_model, model_path)\n",
        "        print(f\"ğŸ’¾ MÃ´ hÃ¬nh tá»‘t nháº¥t Fold {fold+1} Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o: {model_path}\")\n",
        "\n",
        "        # 6. Test\n",
        "        model.load_state_dict(best_model)\n",
        "        test_acc, test_auprc, _ = evaluate(model, data, test_mask, loss_fn)\n",
        "        print(f\"âœ… Test Accuracy: {test_acc:.4f} | AUPRC: {test_auprc:.4f}\")\n",
        "        accs.append(test_acc)\n",
        "        auprcs.append(test_auprc)\n",
        "\n",
        "    print(\"\\nğŸ“Š Tá»•ng káº¿t sau 5 fold:\")\n",
        "    print(f\"Accuracy: {np.mean(accs):.4f} Â± {np.std(accs):.4f}\")\n",
        "    print(f\"AUPRC:    {np.mean(auprcs):.4f} Â± {np.std(auprcs):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DECv2XRbtsoU"
      },
      "outputs": [],
      "source": [
        "run_pretrain_finetune_pipeline(data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}